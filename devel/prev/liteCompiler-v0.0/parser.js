(function () {
  var grammar, GrammarRoot, Grammar;

  /* The Kal Parser
     --------------

     The parser takes an array of tokens generated by the lexer and creates an abstract syntax tree (AST) of sytax nodes such as _Expressions_, _If Statements_, and _Assignment Statements_. The actual grammar definition is defined in the `grammar` module.
      */
  grammar = require('./grammar');
  /*
     The grammar defines a root object (a Kal `File` if you inspect the `grammar` module) that we use to kick off parsing and create a tree.
      */
  GrammarRoot = grammar.GrammarRoot;
  Grammar = grammar.Grammar;
  /*  */
  exports.Grammar = Grammar;

  /*
     The `parse` function is the entry point for the compiler. It creates a token stream and parses it, returning the tree.
      */
  function parse(tokens, comments, options) {
    var ts, AST;
    ts = new TokenStream(tokens, comments, options);
    try{
       AST = new GrammarRoot(ts);
   } catch(e){
       //ts.dump();
       throw(e);
   }
    return AST;
  }

  /*  */
  exports.parse = parse; //a comment

  /*
     The `TokenStream` class allows easy navigation through the array of tokens, keeping track of line numbers and comments.
      */
  function TokenStream(tokens, comments, options) {
    this.tokens = tokens;
    this.comments = comments;
    this.options = options;
    this.goto_token(0);
  }

  TokenStream.prototype.dump = function () {
      this.prev();
      for (var n=0;n<10;n++){
          this.next();
          console.log(this.current.type+'('+this.current.text+')');
      }
  }

  /*
     Go to the next token and return it.
      */
  TokenStream.prototype.next = function () {
    return this.goto_token(this.index + 1);
  }

  /*
     Go back one token and return it.
      */
  TokenStream.prototype.prev = function () {
    return this.goto_token(this.index - 1);
  }

  /*
     Return the next token but stay at the current location in the stream.
      */
  TokenStream.prototype.peek = function (delta_index) {
    var token;
    this.goto_token(this.index + delta_index);
    token = this.current;
    this.goto_token(this.index - delta_index);
    return token;
  }

  /*
     Go to a specific token. Generally this is not called directly; it is used by `next`, `prev`, and `peek`.
      */
  TokenStream.prototype.goto_token = function (index) {
    this.index = index;
    /*
       Return an `EOF` token if we ran out of tokens.
        */
    if (this.index > this.tokens.length - 1) {
      this.current = {type: 'EOF', text: '', line: 0, value: ''};
    } else if (this.index < 0) {
      /*
         Actually error out if we try to read before the beginning of the file. This aborts compilation with a compiler error.
          */
      throw 'Parser Error: tried to read before beginning of file';
    }
     else {
      this.current = this.tokens[this.index];
    }
    /*
       Utility properties for the parser nodes.
        */
    this.type = this.current.type;
    this.text = this.current.text;
    this.value = this.current.value;
    this.line = this.current.line;
    return this.current;
  }

})()